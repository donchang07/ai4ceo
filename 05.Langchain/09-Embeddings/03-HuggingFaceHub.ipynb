{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23050dbd",
   "metadata": {},
   "source": [
    "# Hugging Face\n",
    "\n",
    "Hugging Face Embedding 클래스를 로드해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf71358",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b31c9",
   "metadata": {},
   "source": [
    "- `HuggingFaceEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fadfd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa3d316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 사용자로부터 HuggingFace Inference API 키를 입력받습니다.\n",
    "inference_api_key = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafd3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 허깅페이스 모델/토크나이저를 다운로드 받을 경로\n",
    "# (예시)\n",
    "\n",
    "import os\n",
    "\n",
    "# ./cache/ 경로에 다운로드 받도록 설정\n",
    "os.environ[\"HF_HOME\"] = \"./cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c600022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    "    HuggingFaceBgeEmbeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b6b99",
   "metadata": {},
   "source": [
    "`HuggingFaceEmbeddings` 클래스를 사용하여 임베딩 객체를 생성합니다.\n",
    "\n",
    "- 이 클래스는 Hugging Face의 Transformers 라이브러리에서 제공하는 사전 훈련된 언어 모델을 활용하여 텍스트 임베딩을 생성합니다.\n",
    "- 생성된 `embeddings` 객체는 텍스트를 벡터 표현으로 변환하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0ce876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\donchang\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beeb631588ec43e2b6b7b66defc295ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\donchang\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\course\\05.Langchain\\09-Embeddings\\cache\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936524ab90074008a1850d7fc9a7b83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8158dfee1c4746fb92f1193d5fdc7772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6156b73bc3492abafa29141a5adb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd05badc85a0410bb998a44e3c6bd95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d85f5883554ccab4ba16faccd121da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14745903de4945528fb041557ab2c995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba0d0f7a320415da36b83948ad29f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b04fe28b3944498a05fcaab53de4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924507b167f34b90ba8f5197b0114fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2342d33a0f4fd3af77527d84e4cfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fe29cd13fe4c549e78f0b067ab9ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\donchang\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\course\\05.Langchain\\09-Embeddings\\cache\\hub\\models--BAAI--bge-large-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6061d6383c0148758154229fe04857c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2df64f4b6b34431b5dd8265dc4a716a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/90.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2266d46411fe4d499b86bad28de42f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa3e28e1ce54cbf8e258a70a4a9390b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ceb241fb2104ecfa9962129c6eadff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f928edd14cbb4d989c59e4154d637f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f55890fabb4497aa237ded04784a379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35e976e98294a9589203f69706d6060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dddcbcf8a064fe4a9f6568dcf094634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd0aa4f22cb499f814e2ca25aa8f1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()  # HuggingFace 임베딩을 생성합니다.\n",
    "embeddings = HuggingFaceBgeEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbe067",
   "metadata": {},
   "source": [
    "- `text` 변수에 \"임베딩 테스트를 하기 위한 샘플 문장입니다.\" 라는 문자열을 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9794d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"임베딩 테스트를 하기 위한 샘플 문장입니다.\"  # 테스트용 문서 텍스트를 정의합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3928f021",
   "metadata": {},
   "source": [
    "`embeddings.embed_query(text)`는 주어진 텍스트를 임베딩 벡터로 변환하는 함수입니다.\n",
    "\n",
    "- `text` 매개변수로 전달된 텍스트를 임베딩 모델에 입력하여 벡터 표현을 생성합니다.\n",
    "- 생성된 임베딩 벡터는 `query_result` 변수에 저장됩니다.\n",
    "\n",
    "이 함수는 텍스트를 벡터 공간에 매핑하여 의미적 유사성을 계산하거나 검색에 활용할 수 있는 벡터 표현을 얻는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d73dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0956b",
   "metadata": {},
   "source": [
    "`query_result[:3]`은 `query_result` 리스트의 처음 3개 요소를 슬라이싱(slicing)하여 선택합니다.\n",
    "\n",
    "- 리스트 슬라이싱 문법인 `[start:end]`를 사용하여 `query_result` 리스트의 일부분을 추출합니다.\n",
    "- `start` 인덱스는 포함되고 `end` 인덱스는 제외됩니다. 따라서 `[:3]`은 인덱스 0부터 2까지의 요소를 선택합니다.\n",
    "- 결과적으로 `query_result` 리스트의 첫 번째, 두 번째, 세 번째 요소가 선택됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2612050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.032299287617206573, -0.10691168159246445, -0.02121555432677269]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 결과의 처음 3개 항목을 선택합니다.\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e588b",
   "metadata": {},
   "source": [
    "`embeddings.embed_documents()` 함수를 사용하여 텍스트 문서를 임베딩합니다.\n",
    "\n",
    "- `[text]`를 인자로 전달하여 단일 문서를 리스트 형태로 임베딩 함수에 전달합니다.\n",
    "- 함수 호출 결과로 반환된 임베딩 벡터를 `doc_result` 변수에 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84da1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result = embeddings.embed_documents(\n",
    "    [text]\n",
    ")  # 텍스트를 임베딩하여 문서 벡터를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc2810",
   "metadata": {},
   "source": [
    "## Hugging Face Inference API\n",
    "\n",
    "Hugging Face Inference API를 통해 임베딩 모델에 접근할 수도 있습니다.\n",
    "\n",
    "이 방법은 sentence_transformers를 설치하거나 모델을 로컬에 다운로드할 필요가 없다는 장점이 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf604c2c",
   "metadata": {},
   "source": [
    "HuggingFaceInferenceAPIEmbeddings를 사용하여 텍스트를 임베딩하는 과정을 보여줍니다.\n",
    "\n",
    "- `HuggingFaceInferenceAPIEmbeddings` 클래스를 초기화할 때 `api_key`와 `model_name`을 전달합니다.\n",
    "  - `api_key`는 Hugging Face Inference API의 인증 키입니다.\n",
    "  - `model_name`은 사용할 임베딩 모델의 이름입니다. 여기서는 \"sentence-transformers/all-MiniLM-l6-v2\" 모델을 사용합니다.\n",
    "- `embed_query` 메서드를 호출하여 주어진 `text`를 임베딩합니다.\n",
    "- 임베딩 결과인 `query_result`의 첫 3개 요소를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fe95ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02381495200097561, 0.08707402646541595, 0.07979416847229004]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    # Hugging Face Inference API 키를 설정합니다.\n",
    "    api_key=inference_api_key,\n",
    "    # 사용할 임베딩 모델의 이름을 지정합니다.\n",
    "    model_name=\"sentence-transformers/all-MiniLM-l6-v2\",\n",
    ")\n",
    "\n",
    "# 주어진 텍스트에 대한 쿼리 임베딩을 생성합니다.\n",
    "query_result = embeddings.embed_query(text)\n",
    "# 쿼리 임베딩 결과의 첫 3개 요소를 가져옵니다.\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073b02e",
   "metadata": {},
   "source": [
    "## Hugging Face Hub\n",
    "\n",
    "Hugging Face Hub 패키지를 통해 로컬에서 임베딩을 생성할 수도 있습니다.\n",
    "\n",
    "이를 위해서는 `huggingface_hub` 패키지를 설치해야 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d323ff9",
   "metadata": {},
   "source": [
    "huggingface_hub 라이브러리를 설치합니다.\n",
    "\n",
    "- !pip install 명령어를 사용하여 huggingface_hub 라이브러리를 설치합니다.\n",
    "- huggingface_hub는 Hugging Face에서 제공하는 모델, 데이터셋 등을 쉽게 액세스하고 사용할 수 있도록 도와주는 라이브러리입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814fe654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43997b16",
   "metadata": {},
   "source": [
    "- `HuggingFaceHubEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.\n",
    "- 이 클래스는 Hugging Face Hub에 호스팅된 임베딩 모델을 사용하여 텍스트를 벡터로 변환하는 기능을 제공합니다.\n",
    "- `HuggingFaceHubEmbeddings`는 LangChain 프레임워크에서 임베딩 기능을 확장하기 위해 커뮤니티에서 개발된 모듈입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e7e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceHubEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b278e",
   "metadata": {},
   "source": [
    "HuggingFaceHubEmbeddings 클래스를 사용하여 임베딩 객체를 생성합니다.\n",
    "\n",
    "- `HuggingFaceHubEmbeddings` 클래스는 Hugging Face Hub에 호스팅된 사전 훈련된 임베딩 모델을 사용하여 텍스트를 벡터로 변환합니다.\n",
    "- `embeddings` 변수에 `HuggingFaceHubEmbeddings` 클래스의 인스턴스를 할당합니다.\n",
    "- 이렇게 생성된 `embeddings` 객체는 텍스트 데이터를 벡터로 변환하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa3e8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFaceHub에서 제공하는 임베딩 모델을 사용하여 임베딩 객체를 생성합니다.\n",
    "embeddings = HuggingFaceHubEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39fd3f",
   "metadata": {},
   "source": [
    "- `text` 변수에 \"임베딩 테스트를 하기 위한 샘플 문장입니다.\" 라는 문자열을 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9937bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"임베딩 테스트를 하기 위한 샘플 문장입니다.\"  # 테스트용 문서 텍스트를 정의합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b755927",
   "metadata": {},
   "source": [
    "`embeddings.embed_query(text)`는 주어진 텍스트를 임베딩 벡터로 변환하는 함수입니다.\n",
    "\n",
    "- `text` 매개변수로 전달된 텍스트를 임베딩 모델에 입력하여 벡터 표현을 생성합니다.\n",
    "- 생성된 임베딩 벡터는 `query_result` 변수에 저장됩니다.\n",
    "\n",
    "이 함수는 텍스트를 벡터 공간에 매핑하여 의미적 유사성을 계산하거나 검색에 활용할 수 있는 벡터 표현을 얻는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e95e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cca18c",
   "metadata": {},
   "source": [
    "임베딩된 차원을 수를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "184d5dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차원을 확인합니다.\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a24c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.032299287617206573, -0.10691168159246445, -0.02121555432677269]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 결과의 처음 3개 항목을 선택합니다.\n",
    "query_result[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
