{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402bf426",
   "metadata": {},
   "source": [
    "## 설치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU langchain umap-learn scikit-learn langchain_community tiktoken langchain-openai langchainhub chromadb langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7554354",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval\n",
    "\n",
    "[RAPTOR](https://arxiv.org/pdf/2401.18059.pdf) 논문은 문서의 색인 생성 및 검색에 대한 흥미로운 접근 방식을 제시합니다.\n",
    "\n",
    "```\n",
    "목적:\n",
    "\n",
    "대량의 문서에서 효과적으로 정보를 추출하고 요약하는 것\n",
    "기존 RAG(Retrieval-Augmented Generation) 시스템의 한계 극복\n",
    "\n",
    "\n",
    "주요 특징:\n",
    "\n",
    "트리 구조를 사용한 계층적 정보 처리\n",
    "재귀적 추상화 과정\n",
    "\n",
    "\n",
    "작동 원리:\n",
    "a. 문서 분할:\n",
    "\n",
    "긴 문서를 작은 청크(chunk)로 분할\n",
    "\n",
    "b. 트리 구조 생성:\n",
    "\n",
    "분할된 청크를 바탕으로 트리 구조 생성\n",
    "각 노드는 문서의 일부분을 나타냄\n",
    "\n",
    "c. 상향식 처리:\n",
    "\n",
    "트리의 말단 노드부터 시작하여 상위로 이동\n",
    "각 노드에서 LLM을 사용하여 정보 추상화 및 요약\n",
    "\n",
    "d. 재귀적 추상화:\n",
    "\n",
    "하위 노드의 요약을 결합하여 상위 노드의 요약 생성\n",
    "이 과정을 트리의 루트 노드까지 반복\n",
    "\n",
    "e. 최종 요약:\n",
    "\n",
    "루트 노드에서 전체 문서의 최종 요약 생성\n",
    "\n",
    "\n",
    "장점:\n",
    "\n",
    "대규모 문서 처리 가능\n",
    "계층적 정보 구조 유지\n",
    "문맥 유지와 정보 손실 최소화\n",
    "기존 RAG 시스템보다 더 정확하고 포괄적인 요약 생성\n",
    "\n",
    "\n",
    "응용 분야:\n",
    "\n",
    "학술 논문 요약\n",
    "법률 문서 분석\n",
    "기업 보고서 요약\n",
    "뉴스 기사 종합\n",
    "\n",
    "\n",
    "기술적 구현:\n",
    "\n",
    "LLM(예: GPT 모델)을 사용한 각 노드의 처리\n",
    "트리 구조 관리를 위한 알고리즘\n",
    "효율적인 병렬 처리 가능\n",
    "\n",
    "\n",
    "도전 과제:\n",
    "\n",
    "계산 비용 관리\n",
    "적절한 트리 구조 설계\n",
    "노드 간 정보 전달의 최적화\n",
    "\n",
    "\n",
    "\n",
    "RAPTOR는 특히 복잡하고 길이가 긴 문서에서 중요한 정보를 추출하고 요약하는 데 효과적입니다.\n",
    "이 방법은 기존 RAG 시스템의 한계를 극복하고, 더 구조화되고 정확한 정보 추출을 가능하게 합니다. \n",
    "하지만 계산 비용이 높을 수 있으므로, 실제 적용 시에는 이를 고려해야 합니다. \n",
    "```\n",
    "구현방법\n",
    "\n",
    "- `leafs`는 시작 문서 집합입니다.\n",
    "- leafs는 임베딩되어 클러스터링됩니다.\n",
    "- 그런 다음 클러스터는 유사한 문서들 간의 정보를 더 높은 수준(더 추상적인)으로 요약합니다.\n",
    "\n",
    "이 과정은 재귀적으로 수행되어, 원본 문서(`leafs`)에서 더 추상적인 요약으로 이어지는 \"트리\"를 형성합니다.\n",
    "\n",
    "이를 다양한 규모에서 적용할 수 있습니다; `leafs`는 다음과 같을 수 있습니다:\n",
    "\n",
    "- 단일 문서에서의 텍스트 청크(논문에서 보여준 것처럼)\n",
    "- 전체 문서(아래에서 보여주는 것처럼)\n",
    "\n",
    "더 긴 컨텍스트의 LLMs를 사용하면, 전체 문서에 대해 이 작업을 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c9f09",
   "metadata": {},
   "source": [
    "### 문서\n",
    "\n",
    "LangChain의 LCEL 문서에 이를 적용해 봅시다.\n",
    "\n",
    "이 경우, 각 `doc`은 LCEL 문서의 고유한 웹 페이지입니다.\n",
    "\n",
    "콘텍스트는 2,000 토큰 미만에서 10,000 토큰 이상까지 다양합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba7426",
   "metadata": {},
   "source": [
    "웹 문서에서 텍스트 데이터를 추출하고, 텍스트의 토큰 수를 계산하여 히스토그램으로 시각화하는 과정을 설명합니다.\n",
    "\n",
    "- `tiktoken` 라이브러리를 사용하여 주어진 인코딩 이름에 따라 문자열의 토큰 수를 계산합니다.\n",
    "- `RecursiveUrlLoader` 클래스를 사용하여 지정된 URL에서 웹 문서를 재귀적으로 로드합니다. 이 과정에서 `BeautifulSoup`를 활용하여 HTML 문서에서 텍스트를 추출합니다.\n",
    "- 여러 URL에서 문서를 로드하여 모든 텍스트 데이터를 하나의 리스트에 모읍니다.\n",
    "- 각 문서 텍스트에 대해 `num_tokens_from_string` 함수를 호출하여 토큰 수를 계산하고, 이를 리스트에 저장합니다.\n",
    "- `matplotlib`를 사용하여 계산된 토큰 수의 분포를 히스토그램으로 시각화합니다. 히스토그램은 토큰 수를 x축에, 해당 토큰 수를 가진 문서의 빈도수를 y축에 나타냅니다.\n",
    "- 히스토그램은 데이터의 분포를 이해하는 데 도움을 주며, 특히 텍스트 데이터의 길이 분포를 시각적으로 파악할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3506db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    # 주어진 문자열에서 토큰의 개수를 반환합니다.\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "# LCEL 문서 로드\n",
    "url = \"https://python.langchain.com/docs/expression_language/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# PydanticOutputParser를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_pydantic = loader.load()\n",
    "\n",
    "# Self Query를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_sq = loader.load()\n",
    "\n",
    "# 문서 텍스트\n",
    "docs.extend([*docs_pydantic, *docs_sq])\n",
    "docs_texts = [d.page_content for d in docs]\n",
    "\n",
    "# 각 문서에 대한 토큰 수 계산\n",
    "counts = [num_tokens_from_string(d, \"cl100k_base\") for d in docs_texts]\n",
    "\n",
    "# 토큰 수의 히스토그램을 그립니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(counts, bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Token Counts in LCEL Documents\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "# 히스토그램을 표시합니다.\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9d8ad",
   "metadata": {},
   "source": [
    "문서 텍스트를 정렬하고 연결하여 토큰 수를 계산하는 과정을 설명합니다.\n",
    "\n",
    "- 문서(`docs`)를 메타데이터의 \"source\" 키를 기준으로 정렬합니다.\n",
    "- 정렬된 문서 리스트를 역순으로 뒤집습니다.\n",
    "- 역순으로 된 문서의 내용을 특정 구분자(`\"\\n\\n\\n --- \\n\\n\\n\"`)를 사용하여 연결합니다.\n",
    "- 연결된 내용의 토큰 수를 `num_tokens_from_string` 함수를 사용하여 계산하고, 이를 출력합니다. 이때, `\"cl100k_base\"` 모델을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0a783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 5175\n"
     ]
    }
   ],
   "source": [
    "# 문서 텍스트를 연결합니다.\n",
    "# 문서를 출처 메타데이터 기준으로 정렬합니다.\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))  # 정렬된 문서를 역순으로 배열합니다.\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [\n",
    "        # 역순으로 배열된 문서의 내용을 연결합니다.\n",
    "        doc.page_content\n",
    "        for doc in d_reversed\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Num tokens in all context: %s\"  # 모든 문맥에서의 토큰 수를 출력합니다.\n",
    "    % num_tokens_from_string(concatenated_content, \"cl100k_base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a33263",
   "metadata": {},
   "source": [
    "`RecursiveCharacterTextSplitter`를 사용하여 텍스트를 분할하는 과정을 설명합니다.\n",
    "\n",
    "- `chunk_size_tok` 변수를 설정하여, 각 텍스트 청크의 크기를 2000 토큰으로 지정합니다.\n",
    "- `RecursiveCharacterTextSplitter`의 `from_tiktoken_encoder` 메소드를 사용하여 텍스트 분할기를 초기화합니다. 여기서 청크 크기(`chunk_size`)와 청크 간 겹침(`chunk_overlap`)을 0으로 설정합니다.\n",
    "- 초기화된 텍스트 분할기의 `split_text` 메소드를 호출하여, `concatenated_content`라는 변수에 저장된 연결된 텍스트를 분할합니다. 분할 결과는 `texts_split` 변수에 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8982e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할을 위한 코드\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size_tok = 2000  # 토큰의 청크 크기를 설정합니다.\n",
    "# 재귀적 문자 텍스트 분할기를 초기화합니다. 토큰 인코더를 사용하여 청크 크기와 중복을 설정합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=chunk_size_tok, chunk_overlap=0\n",
    ")\n",
    "texts_split = text_splitter.split_text(\n",
    "    concatenated_content\n",
    ")  # 주어진 텍스트를 분할합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1758e3",
   "metadata": {},
   "source": [
    "## 모델\n",
    "\n",
    "다양한 모델을 테스트할 수 있으며, 새로운 [Claude3](https://www.anthropic.com/news/claude-3-family) 계열도 포함됩니다.\n",
    "\n",
    "관련 API 키를 설정하는 것을 잊지 마세요.\n",
    "\n",
    "- `OPENAI_API_KEY`, Anthropic 을 사용하는 경우 `ANTHROPIC_API_KEY`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e1803",
   "metadata": {},
   "source": [
    "`ChatOpenAI` 혹은 `ChatAnthropic` + `OpenAIEmbeddings`를 사용하여 챗봇 모델을 구현합니다.\n",
    "\n",
    "- `OpenAIEmbeddings`를 인스턴스화하여 OpenAI의 임베딩 기능을 초기화합니다.\n",
    "- `ChatOpenAI` 혹은 `ChatAnthropic` 을 사용하여 `temperature`를 0으로 설정하고, 챗봇 모델을 초기화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1a8129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0990c",
   "metadata": {},
   "source": [
    "Cache Embedding 을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d18ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# embeddings 인스턴스를 생성합니다.\n",
    "embd = OpenAIEmbeddings(model=\"text-embedding-3-small\", disallowed_special=())\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embd, store, namespace=embd.model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc61f6",
   "metadata": {},
   "source": [
    "모델을 초기화 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48631ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "# ChatOpenAI 모델을 초기화합니다. 모델은 \"gpt-4o\"를 사용합니다.\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "\n",
    "# ChatAnthropic 모델을 초기화합니다. 온도는 0으로 설정하고, 모델은 \"claude-3-5-sonnet-20240620\"를 사용합니다.\n",
    "# model = ChatAnthropic(temperature=0, model=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89741a7",
   "metadata": {},
   "source": [
    "### 트리 구축\n",
    "다음과 같은 방식으로 트리를 구축하는 이유는 데이터의 구조를 효과적으로 파악하고 표현하기 위해서입니다. 각 기법이 가진 장점을 결합해 더 강력하고 유연한 클러스터링 접근법을 만들어냅니다. 구체적인 이유를 살펴보겠습니다:\n",
    "\n",
    "### GMM (가우시안 혼합 모델) 사용:\n",
    "\n",
    "데이터의 복잡한 분포를 모델링할 수 있습니다. 단순한 구형 클러스터가 아닌, 타원형이나 더 복잡한 형태의 클러스터도 포착할 수 있습니다.\n",
    "BIC를 통해 최적의 클러스터 수를 자동으로 결정할 수 있어, 사용자가 임의로 클러스터 수를 정하지 않아도 됩니다.\n",
    "\n",
    "\n",
    "### UMAP(Uniform Manifold Approximation and Projection) 활용:\n",
    "\n",
    "고차원 데이터를 저차원으로 축소하면서도 데이터의 구조를 잘 보존합니다. 이는 시각화와 클러스터링 성능 향상에 도움이 됩니다.\n",
    "비선형적인 데이터 구조도 잘 포착할 수 있어, 복잡한 관계를 가진 데이터에서도 효과적입니다.\n",
    "\n",
    "\n",
    "### 지역 및 전역 클러스터링 병행:\n",
    "\n",
    "데이터의 다양한 스케일의 패턴을 포착할 수 있습니다. 큰 그룹 내의 작은 하위 그룹도 식별할 수 있어, 계층적 구조를 갖는 데이터에 특히 유용합니다.\n",
    "이는 RAG 시스템에서 질문에 대해 관련성 높은 문서를 더 정확하게 검색하는 데 도움이 됩니다.\n",
    "\n",
    "\n",
    "### 임계값 설정:\n",
    "\n",
    "GMM의 확률 기반 접근법을 활용해 데이터 포인트의 클러스터 소속을 더 유연하게 결정할 수 있습니다.\n",
    "하나의 데이터 포인트가 여러 클러스터에 속할 수 있게 함으로써, 경계가 모호한 데이터나 다중 주제를 다루는 문서 등을 더 잘 표현할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "- 이러한 방식으로 트리를 구축하면, 데이터의 복잡한 구조를 잘 반영하는 유연하고 정확한 검색 시스템을 만들 수 있습니다. 이는 RAG 시스템에서 질문에 가장 관련성 높은 정보를 효과적으로 검색하고 활용하는 데 큰 도움이 됩니다.\n",
    "---\n",
    "\n",
    "- GMM 및 임계값 설정에 대한 코드는 아래 두 출처에서 언급된 Sarthi et al의 것입니다:\n",
    "\n",
    "- https://github.com/parthsarthi03/raptor/blob/master/raptor/cluster_tree_builder.py\n",
    "- https://github.com/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/clustering.py\n",
    "\n",
    "두 저자 모두에게 전적인 공로를 인정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd012a",
   "metadata": {},
   "source": [
    "`global_cluster_embeddings` 함수는 임베딩의 글로벌 차원 축소를 수행하기 위해 UMAP을 사용합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)을 UMAP을 사용하여 지정된 차원(`dim`)으로 차원 축소합니다.\n",
    "- `n_neighbors`는 각 포인트를 고려할 이웃의 수를 지정하며, 제공되지 않을 경우 임베딩 수의 제곱근으로 기본 설정됩니다.\n",
    "- `metric`은 UMAP에 사용될 거리 측정 기준을 지정합니다.\n",
    "- 결과로, 지정된 차원으로 축소된 임베딩이 numpy 배열로 반환됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2970a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 42  # 재현성을 위한 고정된 시드 값\n",
    "\n",
    "### --- 위의 인용된 코드에서 주석과 문서화를 추가함 --- ###\n",
    "\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UMAP을 사용하여 임베딩의 전역 차원 축소를 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원.\n",
    "    - n_neighbors: 선택 사항; 각 점을 고려할 이웃의 수.\n",
    "                   제공되지 않으면 임베딩 수의 제곱근으로 기본 설정됩니다.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd077834",
   "metadata": {},
   "source": [
    "임베딩 데이터에 대해 지역 차원 축소를 수행하는 함수 `local_cluster_embeddings`를 구현합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)을 UMAP을 사용하여 지정된 차원(`dim`)으로 차원 축소합니다.\n",
    "- 차원 축소 과정에서 각 점에 대해 고려할 이웃의 수(`num_neighbors`)와 거리 측정 메트릭(`metric`)을 파라미터로 사용합니다.\n",
    "- 최종적으로 차원이 축소된 임베딩을 `numpy` 배열로 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d961ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 지역 차원 축소를 수행합니다. 이는 일반적으로 전역 클러스터링 이후에 사용됩니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원 수.\n",
    "    - num_neighbors: 각 점에 대해 고려할 이웃의 수.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab30f112",
   "metadata": {},
   "source": [
    "`get_optimal_clusters` 함수는 주어진 임베딩 데이터를 기반으로 최적의 클러스터 수를 결정하는 데 사용됩니다. 이 과정은 가우시안 혼합 모델(Gaussian Mixture Model)을 사용하여 베이지안 정보 기준(Bayesian Information Criterion, BIC)을 계산함으로써 수행됩니다.\n",
    "\n",
    "- 입력 임베딩(`embeddings`)은 numpy 배열로 제공됩니다.\n",
    "- 최대 클러스터 수(`max_clusters`)는 고려할 클러스터의 최대 수를 지정합니다. 기본값은 50입니다.\n",
    "- 재현성을 위한 난수 상태(`random_state`)는 고정된 값을 사용합니다.\n",
    "- 함수는 입력 임베딩에 대해 여러 클러스터 수를 시도하며 각각에 대한 BIC 값을 계산합니다.\n",
    "- 최소 BIC 값을 가지는 클러스터 수를 최적의 클러스터 수로 결정하고 반환합니다.\n",
    "\n",
    "이 함수는 클러스터링 문제에서 데이터를 가장 잘 설명하는 클러스터 수를 자동으로 찾는 데 유용하게 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade041a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    가우시안 혼합 모델(Gaussian Mixture Model)을 사용하여 베이지안 정보 기준(BIC)을 통해 최적의 클러스터 수를 결정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - max_clusters: 고려할 최대 클러스터 수.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 발견된 최적의 클러스터 수를 나타내는 정수.\n",
    "    \"\"\"\n",
    "    max_clusters = min(\n",
    "        max_clusters, len(embeddings)\n",
    "    )  # 최대 클러스터 수와 임베딩의 길이 중 작은 값을 최대 클러스터 수로 설정\n",
    "    n_clusters = np.arange(1, max_clusters)  # 1부터 최대 클러스터 수까지의 범위를 생성\n",
    "    bics = []  # BIC 점수를 저장할 리스트\n",
    "    for n in n_clusters:  # 각 클러스터 수에 대해 반복\n",
    "        gm = GaussianMixture(\n",
    "            n_components=n, random_state=random_state\n",
    "        )  # 가우시안 혼합 모델 초기화\n",
    "        gm.fit(embeddings)  # 임베딩에 대해 모델 학습\n",
    "        bics.append(gm.bic(embeddings))  # 학습된 모델의 BIC 점수를 리스트에 추가\n",
    "    return n_clusters[np.argmin(bics)]  # BIC 점수가 가장 낮은 클러스터 수를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27119b8",
   "metadata": {},
   "source": [
    "`GMM_cluster` 함수는 임베딩을 가우시안 혼합 모델(Gaussian Mixture Model, GMM)을 사용하여 클러스터링합니다. 이 과정은 확률 임계값을 기반으로 합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)은 numpy 배열로 제공됩니다.\n",
    "- `threshold`는 임베딩을 특정 클러스터에 할당하기 위한 확률 임계값입니다.\n",
    "- `random_state`는 결과의 재현성을 위한 시드 값입니다.\n",
    "- 최적의 클러스터 수를 결정하기 위해 `get_optimal_clusters` 함수를 호출합니다.\n",
    "- 결정된 클러스터 수를 바탕으로 가우시안 혼합 모델을 초기화하고, 입력된 임베딩에 대해 학습을 수행합니다.\n",
    "- 각 임베딩에 대한 클러스터 할당 확률을 계산하고, 이 확률이 주어진 임계값을 초과하는 경우 해당 임베딩을 클러스터에 할당합니다.\n",
    "- 함수는 최종적으로 임베딩의 클러스터 레이블과 결정된 클러스터 수를 튜플로 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86a6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "    확률 임계값을 기반으로 가우시안 혼합 모델(GMM)을 사용하여 임베딩을 클러스터링합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - threshold: 임베딩을 클러스터에 할당하기 위한 확률 임계값.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 클러스터 레이블과 결정된 클러스터 수를 포함하는 튜플.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)  # 최적의 클러스터 수를 구합니다.\n",
    "    # 가우시안 혼합 모델을 초기화합니다.\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)  # 임베딩에 대해 모델을 학습합니다.\n",
    "    probs = gm.predict_proba(\n",
    "        embeddings\n",
    "    )  # 임베딩이 각 클러스터에 속할 확률을 예측합니다.\n",
    "    # 임계값을 초과하는 확률을 가진 클러스터를 레이블로 선택합니다.\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters  # 레이블과 클러스터 수를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d9bd6",
   "metadata": {},
   "source": [
    "`perform_clustering` 함수는 임베딩에 대해 차원 축소, 가우시안 혼합 모델을 사용한 글로벌 클러스터링, 그리고 각 글로벌 클러스터 내에서의 로컬 클러스터링을 수행하여 클러스터링 결과를 반환합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)에 대해 차원 축소를 수행합니다. 이는 UMAP을 사용하여 지정된 차원(`dim`)으로 임베딩의 차원을 축소하는 과정을 포함합니다.\n",
    "- 차원이 축소된 임베딩에 대해 가우시안 혼합 모델(GMM)을 사용하여 글로벌 클러스터링을 수행합니다. 클러스터 할당은 주어진 확률 임계값(`threshold`)을 기준으로 결정됩니다.\n",
    "- 각 글로벌 클러스터 내에서 추가적인 로컬 클러스터링을 수행합니다. 이 과정은 글로벌 클러스터링 결과를 바탕으로 각 글로벌 클러스터에 속한 임베딩들만을 대상으로 다시 차원 축소 및 GMM 클러스터링을 진행합니다.\n",
    "- 최종적으로, 모든 임베딩에 대해 글로벌 및 로컬 클러스터 ID를 할당하여, 각 임베딩이 속한 클러스터 ID를 담은 리스트를 반환합니다. 이 리스트는 임베딩의 순서에 따라 각 임베딩에 대한 클러스터 ID 배열을 포함합니다.\n",
    "\n",
    "이 함수는 고차원 데이터의 클러스터링을 위해 글로벌 및 로컬 차원에서의 클러스터링을 결합한 접근 방식을 제공합니다. 이를 통해 더 세분화된 클러스터링 결과를 얻을 수 있으며, 복잡한 데이터 구조를 보다 효과적으로 분석할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e97d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 차원 축소, 가우시안 혼합 모델을 사용한 클러스터링, 각 글로벌 클러스터 내에서의 로컬 클러스터링을 순서대로 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩입니다.\n",
    "    - dim: UMAP 축소를 위한 목표 차원입니다.\n",
    "    - threshold: GMM에서 임베딩을 클러스터에 할당하기 위한 확률 임계값입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 각 임베딩의 클러스터 ID를 포함하는 numpy 배열의 리스트입니다.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # 데이터가 충분하지 않을 때 클러스터링을 피합니다.\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # 글로벌 차원 축소\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # 글로벌 클러스터링\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # 각 글로벌 클러스터를 순회하며 로컬 클러스터링 수행\n",
    "    for i in range(n_global_clusters):\n",
    "        # 현재 글로벌 클러스터에 속하는 임베딩 추출\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # 작은 클러스터는 직접 할당으로 처리\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # 로컬 차원 축소 및 클러스터링\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # 로컬 클러스터 ID 할당, 이미 처리된 총 클러스터 수를 조정\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051d771",
   "metadata": {},
   "source": [
    "텍스트 문서의 목록에 대한 임베딩을 생성하는 함수 `embed`를 구현합니다.\n",
    "\n",
    "- 입력으로 텍스트 문서의 목록(`texts`)을 받습니다.\n",
    "- `embd` 객체의 `embed_documents` 메소드를 사용하여 텍스트 문서의 임베딩을 생성합니다.\n",
    "- 생성된 임베딩을 `numpy.ndarray` 형태로 변환하여 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "175963c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts):\n",
    "    # 텍스트 문서 목록에 대한 임베딩을 생성합니다.\n",
    "    #\n",
    "    # 이 함수는 `embd` 객체가 존재한다고 가정하며, 이 객체는 텍스트 목록을 받아 그 임베딩을 반환하는 `embed_documents` 메소드를 가지고 있습니다.\n",
    "    #\n",
    "    # 매개변수:\n",
    "    # - texts: List[str], 임베딩할 텍스트 문서의 목록입니다.\n",
    "    #\n",
    "    # 반환값:\n",
    "    # - numpy.ndarray: 주어진 텍스트 문서들에 대한 임베딩 배열입니다.\n",
    "    text_embeddings = embd.embed_documents(\n",
    "        texts\n",
    "    )  # 텍스트 문서들의 임베딩을 생성합니다.\n",
    "    text_embeddings_np = np.array(text_embeddings)  # 임베딩을 numpy 배열로 변환합니다.\n",
    "    return text_embeddings_np  # 임베딩된 numpy 배열을 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b6b30",
   "metadata": {},
   "source": [
    "`embed_cluster_texts` 함수는 텍스트 목록을 임베딩하고 클러스터링하여, 원본 텍스트, 해당 임베딩, 그리고 할당된 클러스터 라벨을 포함하는 `pandas.DataFrame`을 반환합니다.\n",
    "\n",
    "- 주어진 텍스트 목록에 대해 임베딩을 생성합니다.\n",
    "- 생성된 임베딩을 기반으로 클러스터링을 수행합니다. 이 과정은 사전에 정의된 `perform_clustering` 함수를 사용합니다.\n",
    "- 결과를 저장하기 위해 `pandas.DataFrame`을 초기화합니다.\n",
    "- DataFrame에 원본 텍스트, 임베딩 리스트, 클러스터 라벨을 각각 저장합니다.\n",
    "\n",
    "이 함수는 텍스트 데이터의 임베딩 생성과 클러스터링을 하나의 단계로 결합하여, 텍스트 데이터의 구조적 분석과 그룹화를 용이하게 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351f42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    텍스트 목록을 임베딩하고 클러스터링하여, 텍스트, 그들의 임베딩, 그리고 클러스터 라벨이 포함된 DataFrame을 반환합니다.\n",
    "\n",
    "    이 함수는 임베딩 생성과 클러스터링을 단일 단계로 결합합니다. 임베딩에 대해 클러스터링을 수행하는 `perform_clustering` 함수의 사전 정의된 존재를 가정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리될 텍스트 문서의 목록입니다.\n",
    "\n",
    "    반환값:\n",
    "    - pandas.DataFrame: 원본 텍스트, 그들의 임베딩, 그리고 할당된 클러스터 라벨이 포함된 DataFrame입니다.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # 임베딩 생성\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # 임베딩에 대해 클러스터링 수행\n",
    "    df = pd.DataFrame()  # 결과를 저장할 DataFrame 초기화\n",
    "    df[\"text\"] = texts  # 원본 텍스트 저장\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # DataFrame에 리스트로 임베딩 저장\n",
    "    df[\"cluster\"] = cluster_labels  # 클러스터 라벨 저장\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a3ecd",
   "metadata": {},
   "source": [
    "`fmt_txt` 함수는 `pandas`의 `DataFrame`에서 텍스트 문서를 단일 문자열로 포맷팅합니다.\n",
    "\n",
    "- 입력 파라미터로 `DataFrame`을 받으며, 이 `DataFrame`은 포맷팅할 텍스트 문서를 포함한 'text' 컬럼을 가져야 합니다.\n",
    "- 모든 텍스트 문서는 특정 구분자(\"--- --- \\n --- ---\")를 사용하여 연결되어 단일 문자열로 반환됩니다.\n",
    "- 함수는 연결된 텍스트 문서를 포함하는 단일 문자열을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "903883eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    DataFrame에 있는 텍스트 문서를 단일 문자열로 포맷합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - df: 'text' 열에 포맷할 텍스트 문서가 포함된 DataFrame.\n",
    "\n",
    "    반환값:\n",
    "    - 모든 텍스트 문서가 특정 구분자로 결합된 단일 문자열.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()  # 'text' 열의 모든 텍스트를 리스트로 변환\n",
    "    return \"--- --- \\n --- --- \".join(\n",
    "        unique_txt\n",
    "    )  # 텍스트 문서들을 특정 구분자로 결합하여 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc49b18",
   "metadata": {},
   "source": [
    "텍스트 데이터를 임베딩하고, 클러스터링하며, 각 클러스터에 대한 요약을 생성하는 과정을 수행합니다.\n",
    "\n",
    "- 주어진 텍스트 목록에 대해 임베딩을 생성하고 유사성에 기반한 클러스터링을 진행합니다. 이 과정은 `df_clusters` 데이터프레임을 결과로 합니다. 이 데이터프레임에는 원본 텍스트, 임베딩, 그리고 클러스터 할당 정보가 포함됩니다.\n",
    "- 클러스터 할당을 쉽게 처리하기 위해 데이터프레임 항목을 확장합니다. 각 행은 텍스트, 임베딩, 클러스터를 포함하는 새로운 데이터프레임으로 변환됩니다.\n",
    "- 확장된 데이터프레임에서 고유한 클러스터 식별자를 추출하고, 각 클러스터에 대한 텍스트를 포맷팅하여 요약을 생성합니다. 이 요약은 `df_summary` 데이터프레임에 저장됩니다. 이 데이터프레임은 각 클러스터의 요약, 지정된 세부 수준, 그리고 클러스터 식별자를 포함합니다.\n",
    "- 최종적으로, 함수는 두 개의 데이터프레임을 포함하는 튜플을 반환합니다. 첫 번째 데이터프레임은 원본 텍스트, 임베딩, 클러스터 할당 정보를 포함하며, 두 번째 데이터프레임은 각 클러스터에 대한 요약과 해당 세부 수준, 클러스터 식별자를 포함합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c242240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    텍스트 목록에 대해 임베딩, 클러스터링 및 요약을 수행합니다. 이 함수는 먼저 텍스트에 대한 임베딩을 생성하고,\n",
    "    유사성을 기반으로 클러스터링을 수행한 다음, 클러스터 할당을 확장하여 처리를 용이하게 하고 각 클러스터 내의 내용을 요약합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: 처리할 텍스트 문서 목록입니다.\n",
    "    - level: 처리의 깊이나 세부 사항을 정의할 수 있는 정수 매개변수입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 두 개의 데이터프레임을 포함하는 튜플:\n",
    "      1. 첫 번째 데이터프레임(`df_clusters`)은 원본 텍스트, 그들의 임베딩, 그리고 클러스터 할당을 포함합니다.\n",
    "      2. 두 번째 데이터프레임(`df_summary`)은 각 클러스터에 대한 요약, 지정된 세부 수준, 그리고 클러스터 식별자를 포함합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 텍스트를 임베딩하고 클러스터링하여 'text', 'embd', 'cluster' 열이 있는 데이터프레임을 생성합니다.\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "\n",
    "    # 클러스터를 쉽게 조작하기 위해 데이터프레임을 확장할 준비를 합니다.\n",
    "    expanded_list = []\n",
    "\n",
    "    # 데이터프레임 항목을 문서-클러스터 쌍으로 확장하여 처리를 간단하게 합니다.\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # 확장된 목록에서 새 데이터프레임을 생성합니다.\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # 처리를 위해 고유한 클러스터 식별자를 검색합니다.\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # 요약\n",
    "    template = \"\"\"여기 LangChain 표현 언어 문서의 하위 집합이 있습니다.\n",
    "    \n",
    "    LangChain 표현 언어는 LangChain에서 체인을 구성하는 방법을 제공합니다.\n",
    "    \n",
    "    제공된 문서의 자세한 요약을 제공하십시오.\n",
    "    \n",
    "    문서:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # 각 클러스터 내의 텍스트를 요약을 위해 포맷팅합니다.\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # 요약, 해당 클러스터 및 레벨을 저장할 데이터프레임을 생성합니다.\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95191d59",
   "metadata": {},
   "source": [
    "텍스트 데이터를 재귀적으로 임베딩, 클러스터링 및 요약하는 과정을 구현한 함수입니다.\n",
    "\n",
    "- 주어진 텍스트 리스트를 임베딩, 클러스터링 및 요약하여 각 단계별로 결과를 저장합니다.\n",
    "- 함수는 최대 지정된 재귀 레벨까지 실행되거나, 유일한 클러스터의 수가 1이 될 때까지 반복됩니다.\n",
    "- 각 재귀 단계에서는 현재 레벨의 클러스터링 결과와 요약 결과를 데이터프레임 형태로 반환하고, 이를 결과 딕셔너리에 저장합니다.\n",
    "- 만약 현재 레벨이 최대 재귀 레벨보다 작고, 유일한 클러스터의 수가 1보다 크다면, 현재 레벨의 요약 결과를 다음 레벨의 입력 텍스트로 사용하여 재귀적으로 함수를 호출합니다.\n",
    "- 최종적으로 각 레벨별 클러스터 데이터프레임과 요약 데이터프레임을 포함하는 딕셔너리를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c417dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    지정된 레벨까지 또는 고유 클러스터의 수가 1이 될 때까지 텍스트를 재귀적으로 임베딩, 클러스터링, 요약하여\n",
    "    각 레벨에서의 결과를 저장합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리할 텍스트들.\n",
    "    - level: int, 현재 재귀 레벨 (1에서 시작).\n",
    "    - n_levels: int, 재귀의 최대 깊이.\n",
    "\n",
    "    반환값:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], 재귀 레벨을 키로 하고 해당 레벨에서의 클러스터 DataFrame과 요약 DataFrame을 포함하는 튜플을 값으로 하는 사전.\n",
    "    \"\"\"\n",
    "    results = {}  # 각 레벨에서의 결과를 저장할 사전\n",
    "\n",
    "    # 현재 레벨에 대해 임베딩, 클러스터링, 요약 수행\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # 현재 레벨의 결과 저장\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # 추가 재귀가 가능하고 의미가 있는지 결정\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # 다음 레벨의 재귀 입력 텍스트로 요약 사용\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # 다음 레벨의 결과를 현재 결과 사전에 병합\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2de5a73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문서의 개수\n",
    "len(docs_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e429ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 1 clusters--\n",
      "LangChain Expression Language (LCEL)는 LangChain에서 체인을 구성하는 선언적 방법을 제공합니다. LCEL은 프로토타입을 생산에 투입하는 것을 지원하도록 설계되었으며, 가장 간단한 \"프롬프트 + LLM\" 체인부터 수백 단계의 복잡한 체인까지 코드 변경 없이 생산에 투입할 수 있습니다. LCEL을 사용하는 이유 중 몇 가지는 다음과 같습니다:\n",
      "\n",
      "- **스트리밍 지원**: LCEL로 체인을 구축하면 최상의 첫 번째 토큰 시간(첫 번째 출력 청크가 나올 때까지 걸린 시간)을 얻을 수 있습니다. 이는 일부 체인에서 LLM에서 스트리밍 출력 파서로 토큰을 스트리밍하고, LLM 제공자가 원시 토큰을 출력하는 속도로 파싱된 증분 청크를 받을 수 있음을 의미합니다.\n",
      "- **비동기 지원**: LCEL로 구축된 모든 체인은 동기 API(예: 프로토타이핑 중인 Jupyter 노트북에서)와 비동기 API(예: LangServe 서버에서) 모두에서 호출할 수 있습니다. 이를 통해 프로토타입과 생산에서 동일한 코드를 사용하고, 뛰어난 성능을 제공하며, 동일한 서버에서 많은 동시 요청을 처리할 수 있습니다.\n",
      "- **병렬 실행 최적화**: LCEL 체인에 병렬로 실행할 수 있는 단계가 있는 경우(예: 여러 검색기에서 문서를 가져올 때), 동기 및 비동기 인터페이스 모두에서 자동으로 이를 수행하여 가능한 가장 작은 대기 시간을 제공합니다.\n",
      "- **재시도 및 대체**: LCEL 체인의 모든 부분에 대해 재시도 및 대체를 구성할 수 있습니다. 이는 규모에서 체인을 더욱 신뢰할 수 있게 만드는 훌륭한 방법입니다.\n",
      "- **중간 결과 접근**: 더 복잡한 체인의 경우 최종 출력이 생성되기 전에 중간 단계의 결과에 액세스하는 것이 종종 매우 유용합니다. 이를 통해 최종 사용자에게 무언가가 진행되고 있음을 알리거나 체인을 디버깅할 수 있습니다.\n",
      "- **입력 및 출력 스키마**: 입력 및 출력 스키마는 체인의 구조로부터 추론된 Pydantic 및 JSONSchema 스키마를 모든 LCEL 체인에 제공합니다. 이는 입력 및 출력의 유효성 검사에 사용될 수 있으며 LangServe의 중요한 부분입니다.\n",
      "- **LangSmith 추적**: 체인이 점점 더 복잡해짐에 따라 각 단계에서 정확히 무슨 일이 일어나고 있는지 이해하는 것이 점점 더 중요해집니다. LCEL을 사용하면 모든 단계가 LangSmith에 자동으로 기록되어 최대한의 관찰 가능성과 디버깅 가능성을 제공합니다.\n",
      "- **LangServe 배포**: LCEL로 생성된 모든 체인은 LangServe를 사용하여 쉽게 배포할 수 있습니다.\n",
      "\n",
      "또한, LCEL은 출력 파서, 자체 쿼리 검색기 등 다양한 구성 요소와 함께 사용되어 구조화된 출력을 추출하고, 문서의 메타데이터에 대한 필터를 적용하는 등의 기능을 제공합니다. 이러한 기능은 LangChain을 사용하여 더 효율적이고 강력한 언어 모델 기반 애플리케이션을 구축하는 데 도움이 됩니다."
     ]
    }
   ],
   "source": [
    "# 트리 구축\n",
    "leaf_texts = docs_texts  # 문서 텍스트를 리프 텍스트로 설정\n",
    "results = recursive_embed_cluster_summarize(\n",
    "    leaf_texts, level=1, n_levels=3\n",
    ")  # 재귀적으로 임베딩, 클러스터링 및 요약을 수행하여 결과를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314fe08",
   "metadata": {},
   "source": [
    "논문에서는 `collapsed tree retrieval`이 최고의 성능을 보고하고 있습니다.\n",
    "\n",
    "이는 트리 구조를 단일 계층으로 평탄화한 다음, 모든 노드에 대해 동시에 k-최근접 이웃(kNN) 검색을 적용하는 과정을 포함합니다.\n",
    "\n",
    "아래에서 이 과정을 간단히 수행합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af418d79",
   "metadata": {},
   "source": [
    "`Chroma` 벡터 저장소를 사용하여 텍스트 데이터의 벡터화 및 검색 가능한 저장소를 구축하는 과정을 설명합니다.\n",
    "\n",
    "- 초기에 `leaf_texts`에 저장된 텍스트 데이터를 `all_texts` 변수에 복사합니다.\n",
    "- 결과 데이터(`results`)를 순회하며 각 레벨에서 요약된 텍스트를 추출하고, 이를 `all_texts`에 추가합니다.\n",
    "  - 각 레벨의 `DataFrame`에서 `summaries` 컬럼의 값을 리스트로 변환하여 추출합니다.\n",
    "  - 추출된 요약문을 `all_texts`에 추가합니다.\n",
    "- 모든 텍스트 데이터(`all_texts`)를 사용하여 `Chroma` 벡터 저장소를 구축합니다.\n",
    "  - `Chroma.from_texts` 함수를 호출하여 텍스트 데이터를 벡터화하고, 벡터 저장소를 생성합니다.\n",
    "  - 생성된 벡터 저장소를 검색 가능하게 만들기 위해 `.as_retriever()` 메소드를 사용하여 검색기(retriever)를 초기화합니다.\n",
    "\n",
    "이 과정을 통해, 다양한 레벨의 요약문을 포함한 텍스트 데이터를 벡터화하고, 이를 기반으로 검색 가능한 `Chroma` 벡터 저장소를 구축합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbd18b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# leaf_texts를 복사하여 all_texts를 초기화합니다.\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# 각 레벨의 요약을 추출하여 all_texts에 추가하기 위해 결과를 순회합니다.\n",
    "for level in sorted(results.keys()):\n",
    "    # 현재 레벨의 DataFrame에서 요약을 추출합니다.\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # 현재 레벨의 요약을 all_texts에 추가합니다.\n",
    "    all_texts.extend(summaries)\n",
    "\n",
    "# 이제 all_texts를 사용하여 FAISS vectorstore를 구축합니다.\n",
    "vectorstore = FAISS.from_texts(texts=all_texts, embedding=embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eea66d",
   "metadata": {},
   "source": [
    "DB 를 로컬에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f67a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DB_INDEX = \"RAPTOR\"\n",
    "\n",
    "# 로컬에 FAISS DB 인덱스가 이미 존재하는지 확인하고, 그렇다면 로드하여 vectorstore와 병합한 후 저장합니다.\n",
    "if os.path.exists(DB_INDEX):\n",
    "    local_index = FAISS.load_local(DB_INDEX, embd)\n",
    "    local_index.merge_from(vectorstore)\n",
    "    local_index.save_local(DB_INDEX)\n",
    "else:\n",
    "    vectorstore.save_local(folder_path=DB_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "398b4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever 생성\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da0f7e",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation(RAG) 체인을 정의하고 특정 코드 예제를 요청하는 방법을 구현합니다.\n",
    "\n",
    "- `hub.pull`을 사용하여 RAG 프롬프트를 불러옵니다.\n",
    "- 문서 포맷팅을 위한 `format_docs` 함수를 정의합니다. 이 함수는 문서의 페이지 내용을 연결하여 반환합니다.\n",
    "- RAG 체인을 구성합니다. 이 체인은 검색기(`retriever`)로부터 문맥을 가져오고, `format_docs` 함수로 포맷팅한 후, 질문을 처리합니다.\n",
    "- `RunnablePassthrough()`를 사용하여 질문을 그대로 전달합니다.\n",
    "- 체인은 프롬프트, 모델, 그리고 `StrOutputParser()`를 통해 최종 출력을 문자열로 파싱합니다.\n",
    "- `rag_chain.invoke` 메소드를 사용하여 \"How to define a RAG chain? Give me a specific code example.\"라는 질문을 처리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9c26dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 문서 포스트 프로세싱\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 문서의 페이지 내용을 이어붙여 반환합니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG 체인 정의\n",
    "rag_chain = (\n",
    "    # 검색 결과를 포맷팅하고 질문을 처리합니다.\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt  # 프롬프트를 적용합니다.\n",
    "    | model  # 모델을 적용합니다.\n",
    "    | StrOutputParser()  # 문자열 출력 파서를 적용합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c647f82",
   "metadata": {},
   "source": [
    "[LangSmith 링크](https://smith.langchain.com/public/178afde0-8dcc-472f-8c47-233fe81cbbad/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0efdda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Expression Language (LCEL)는 LangChain에서 체인을 구성하는 선언적 방법을 제공하며, 프로토타입을 생산에 투입하는 것을 지원하도록 설계되었습니다. LCEL은 스트리밍 지원, 비동기 지원, 병렬 실행 최적화, 재시도 및 대체, 중간 결과 접근, 입력 및 출력 스키마, LangSmith 추적, LangServe 배포 등 다양한 기능을 제공합니다. 이러한 기능들은 LangChain을 사용하여 언어 모델 기반 애플리케이션을 더 효율적이고 강력하게 구축하는 데 도움이 됩니다."
     ]
    }
   ],
   "source": [
    "# 추상적인 질문 실행\n",
    "_ = rag_chain.invoke(\"전체 문서의 핵심 주제에 대해 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b34ee",
   "metadata": {},
   "source": [
    "[LangSmith 링크](https://smith.langchain.com/public/1d72738b-f378-4676-9961-dd12fe424918/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e8193fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from langchain.output_parsers import PydanticOutputParser\n",
      "from langchain_core.prompts import PromptTemplate\n",
      "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
      "from langchain_openai import OpenAI\n",
      "\n",
      "# Define your desired data structure.\n",
      "class Joke(BaseModel):\n",
      "    setup: str = Field(description=\"question to set up a joke\")\n",
      "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
      "    # You can add custom validation logic easily with Pydantic.\n",
      "    @validator(\"setup\")\n",
      "    def question_ends_with_question_mark(cls, field):\n",
      "        if field[-1] != \"?\":\n",
      "            raise ValueError(\"Badly formed question!\")\n",
      "        return field\n",
      "\n",
      "# Set up a parser + inject instructions into the prompt template.\n",
      "parser = PydanticOutputParser(pydantic_object=Joke)\n",
      "prompt = PromptTemplate(\n",
      "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
      "    input_variables=[\"query\"],\n",
      "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
      ")\n",
      "\n",
      "# And a query intended to prompt a language model to populate the data structure.\n",
      "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
      "prompt_and_model = prompt | model\n",
      "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
      "parser.invoke(output)\n",
      "```"
     ]
    }
   ],
   "source": [
    "# Low Level 질문 실행\n",
    "_ = rag_chain.invoke(\"PydanticOutputParser 을 활용한 예시 코드를 작성해 주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e4e23",
   "metadata": {},
   "source": [
    "[LangSmith 링크](https://smith.langchain.com/public/bd725efb-d854-4d0e-b34b-52748dddcf4b/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52666307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-querying 방법은 자연어 질의를 받아 이를 구조화된 쿼리로 변환하고, 해당 쿼리를 자신의 벡터 스토어에 적용하여 문서의 내용과 메타데이터에 대한 의미적 유사성 비교 및 필터링을 수행하는 방식입니다. 예를 들어, 영화에 대한 요약과 메타데이터를 포함하는 문서 집합에서 특정 조건을 만족하는 문서를 검색할 수 있습니다. 아래는 Python을 사용한 self-querying 예시 코드입니다:\n",
      "\n",
      "```python\n",
      "from langchain.chains.query_constructor.base import AttributeInfo\n",
      "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "metadata_field_info = [\n",
      "    AttributeInfo(name=\"genre\", description=\"The genre of the movie.\", type=\"string\"),\n",
      "    AttributeInfo(name=\"year\", description=\"The year the movie was released\", type=\"integer\"),\n",
      "    AttributeInfo(name=\"director\", description=\"The name of the movie director\", type=\"string\"),\n",
      "    AttributeInfo(name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"),\n",
      "]\n",
      "\n",
      "document_content_description = \"Brief summary of a movie\"\n",
      "llm = ChatOpenAI(temperature=0)\n",
      "retriever = SelfQueryRetriever.from_llm(\n",
      "    llm,\n",
      "    vectorstore,\n",
      "    document_content_description,\n",
      "    metadata_field_info,\n",
      ")\n",
      "\n",
      "# Example query\n",
      "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")\n",
      "```\n",
      "\n",
      "이 코드는 영화에 대한 요약과 메타데이터를 포함하는 문서 집합에서 평점이 8.5 이상인 영화를 찾는 예시입니다."
     ]
    }
   ],
   "source": [
    "# Low Level 질문 실행\n",
    "_ = rag_chain.invoke(\"self-querying 방법과 예시 코드를 작성해 주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf86113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
