{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain of Density: https://arxiv.org/pdf/2309.04269.pdf\n",
    "```\n",
    "RAG에서의 Chain of Density:\n",
    "RAG 시스템에서 CoD는 검색된 문서나 지식을 더 효과적으로 활용하여 높은 품질의 \n",
    "응답을 생성하는 데 사용될 수 있습니다.\n",
    "\n",
    "목적:\n",
    "\n",
    "검색된 정보를 더 밀도 있게 활용\n",
    "응답의 정보 밀도를 높이면서도 간결성 유지\n",
    "\n",
    "RAG에서의 적용:\n",
    "a. 초기 응답 생성: 검색된 문서를 바탕으로 기본적인 응답 생성\n",
    "b. 밀도 증가: 추가 정보나 누락된 중요 개념을 점진적으로 통합\n",
    "c. 재구성: 응답을 재구성하여 더 풍부하고 정확한 정보 제공\n",
    "\n",
    "장점:\n",
    "\n",
    "더 포괄적이고 정확한 응답 생성\n",
    "검색된 문서의 정보를 더 효율적으로 활용\n",
    "불필요한 반복이나 중복 정보 감소\n",
    "\n",
    "구현 방법:\n",
    "\n",
    "다단계 프롬프팅: LLM에 여러 단계의 프롬프트를 제공하여 응답을 점진적으로 개선\n",
    "반복적 검색: 초기 응답을 바탕으로 추가 정보 검색 및 통합\n",
    "\n",
    "예시 과정:\n",
    "a. 초기 응답 생성\n",
    "b. 누락된 중요 정보 식별\n",
    "c. 추가 정보 검색 또는 기존 검색 결과에서 추출\n",
    "d. 새로운 정보를 통합하여 응답 개선\n",
    "e. 필요시 이 과정을 반복\n",
    "\n",
    "도전 과제:\n",
    "\n",
    "적절한 밀도 수준 결정\n",
    "응답의 일관성 유지\n",
    "계산 비용과 시간 관리\n",
    "\n",
    "RAG 시스템 개선:\n",
    "CoD를 통해 RAG 시스템은 단순히 정보를 검색하고 요약하는 것을 넘어, \n",
    "더 깊이 있고 맥락에 맞는 응답을 생성할 수 있습니다.\n",
    "\n",
    "Chain of Density를 RAG에 적용함으로써, 시스템은 더 정교하고 정보가 \n",
    "풍부한 응답을 생성할 수 있습니다. 이는 특히 복잡한 질문이나 다양한 \n",
    "정보 소스를 필요로 하는 상황에서 유용할 수 있습니다. \n",
    "그러나 이 과정이 응답 생성 시간을 늘릴 수 있으므로, \n",
    "실시간 응답이 필요한 경우에는 적절한 균형을 찾는 것이 중요합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import textwrap\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Load some data to summarize\n",
    "loader = WebBaseLoader(\"https://teddylee777.github.io/data-science/optuna/\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "\n",
    "# Get this prompt template\n",
    "# https://smith.langchain.com/hub/lawwu/chain_of_density?organizationId=4238ea05-3ccc-5451-bdf6-3935d7cf64b8\n",
    "prompt = hub.pull(\"lawwu/chain_of_density\")\n",
    "\n",
    "# The chat model output is a JSON list of dicts, with SimpleJsonOutputParser\n",
    "# we can convert it o a dict, and it suppors streaming.\n",
    "json_parser = SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"ARTICLE\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.1)\n",
    "    | json_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Missing_Entities': 'Optuna',\n",
       "  'Denser_Summary': 'This article discusses Optuna, a hyperparameter optimization library for machine learning. Optuna provides a simple and efficient way to search for the best hyperparameters for a given model. It uses a variety of search algorithms to explore the hyperparameter space and find the optimal values. With Optuna, you can easily tune the hyperparameters of your machine learning models and improve their performance.'},\n",
       " {'Missing_Entities': 'trial.suggest_categorical()',\n",
       "  'Denser_Summary': 'Optuna provides a suggest_categorical() function that allows you to suggest categorical hyperparameters for optimization. This function takes the name of the hyperparameter and a list of choices as input. Optuna will then explore different combinations of these choices to find the best value for the hyperparameter. By using suggest_categorical(), you can easily optimize categorical hyperparameters and improve the performance of your machine learning models.'},\n",
       " {'Missing_Entities': 'trial.suggest_int()',\n",
       "  'Denser_Summary': 'Another useful function provided by Optuna is suggest_int(), which allows you to suggest integer hyperparameters for optimization. You can specify the name of the hyperparameter, the lower and upper bounds, and an optional step size. Optuna will then search for the best integer value within the specified range. By using suggest_int(), you can efficiently optimize integer hyperparameters and enhance the performance of your machine learning models.'},\n",
       " {'Missing_Entities': 'trial.suggest_float()',\n",
       "  'Denser_Summary': 'In addition to categorical and integer hyperparameters, Optuna also supports optimization of float hyperparameters. The suggest_float() function allows you to suggest float values within a specified range. You can specify the name of the hyperparameter, the lower and upper bounds, and an optional step size. Optuna will then search for the best float value within the specified range. By using suggest_float(), you can effectively optimize float hyperparameters and achieve better performance in your machine learning models.'},\n",
       " {'Missing_Entities': 'objective function',\n",
       "  'Denser_Summary': \"The objective function is a key component in Optuna's optimization process. It defines the evaluation metric that Optuna uses to assess the performance of different hyperparameter configurations. By providing a well-defined objective function, you can guide Optuna to search for the hyperparameters that maximize or minimize the desired metric. The objective function takes the trial object, the model, the input data, the target variable, and the evaluation metric as inputs. By optimizing the objective function, you can find the best hyperparameters for your machine learning models.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"박정현 서울대 EPM 연구원; 데이터사이언스, 머신러닝, 인공지능 정의; 데이터사이언스 대학원 및 인공지능 대학원 설립; '인공지능 국가전략' 발표\",\n",
      "        \"Denser_Summary\": \"이 기사는 데이터사이언스, 머신러닝, 인공지능에 대한 기본적인 이해와 이 분야들의 차이점을 설명합니다. 박정현 서울대 EPM 연구원은 이 분야들이 실생활에 어떻게 적용되고 있는지, 그리고 이 분야에서 일하고자 하는 사람들을 위한 조언을 제공합니다. 또한, 데이터사이언스 대학원 및 인공지능 대학원의 설립과 '인공지능 국가전략' 발표와 같은 교육 및 정책적 변화에 대해서도 언급합니다. 이 글은 데이터사이언스, 머신러닝, 인공지능의 정의를 포함하여 이 분야의 기초적인 지식을 제공하고자 합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"데이터사이언스의 이론적, 실용적 측면; 튜링테스트; 지도학습, 비지도 학습\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 실용적 적용을 설명하며, 데이터사이언스 대학원과 '인공지능 국가전략' 발표를 언급합니다. 데이터사이언스는 이론적, 실용적 측면으로 나뉘며, 인공지능의 이해를 위해 튜링테스트를, 머신러닝은 지도학습과 비지도 학습으로 구분하여 설명합니다. 이 글은 이 분야에 대한 깊은 이해를 돕고, 관련 교육 및 정책 변화에 대해 논합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"알파고와 이세돌 대결; OpenAI의 GPT-3 공개; 머신러닝의 실생활 적용 예\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 기본 개념과 이론적, 실용적 측면을 소개합니다. 알파고와 이세돌의 대결, OpenAI의 GPT-3 공개와 같은 사례를 통해 이 기술들의 실생활 적용을 설명하며, 데이터사이언스 대학원 설립과 '인공지능 국가전략' 발표를 언급합니다. 또한, 튜링테스트와 머신러닝의 지도학습, 비지도 학습을 통해 인공지능의 발전 방향을 논합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"스팸 메일 필터링; k-means 알고리즘; 강화학습\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 알파고, GPT-3 같은 실제 적용 사례를 소개합니다. 데이터사이언스 대학원, '인공지능 국가전략' 발표, 튜링테스트, 지도학습, 비지도 학습의 중요성을 강조합니다. 스팸 메일 필터링, k-means 알고리즘, 강화학습 등 머신러닝의 다양한 적용 예를 통해 이 기술들의 실용성을 설명합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 알파고, GPT-3 같은 실제 적용 사례를 소개합니다. 데이터사이언스 대학원, '인공지능 국가전략' 발표, 튜링테스트, 지도학습, 비지도 학습의 중요성을 강조합니다. 스팸 메일 필터링, k-means 알고리즘, 강화학습 등 머신러닝의 다양한 적용 예를 통해 이 기술들의 실용성을 설명합니다.\"\n",
      "    }\n",
      "]\n",
      "```박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 알파고, GPT-3 같은 실제 적용 사례를 소개합니다. 데이터사이언스 대학원, '인공지능 국가전략' 발표, 튜링테스트, 지도학습, 비지도 학습의 중요성을 강조합니다. 스팸 메일 필터링, k-means 알고리즘, 강화학습 등 머신러닝의 다양한 적용 예를 통해 이 기술들의 실용성을 설명합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import json\n",
    "\n",
    "\n",
    "# Load some data to summarize\n",
    "loader = WebBaseLoader(\n",
    "    \"https://www.aitimes.com/news/articleView.html?idxno=131777\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "# Load the prompt\n",
    "# prompt = hub.pull(\"langchain-ai/chain-of-density:4f55305e\")\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Article: {ARTICLE}\n",
    "You will generate increasingly concise, entity-dense summaries of the above article. \n",
    "\n",
    "Repeat the following 2 steps 5 times. \n",
    "\n",
    "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \n",
    "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n",
    "\n",
    "A missing entity is:\n",
    "- relevant to the main story, \n",
    "- specific yet concise (50 words or fewer), \n",
    "- novel (not in the previous summary), \n",
    "- faithful (present in the article), \n",
    "- anywhere (can be located anywhere in the article).\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n",
    "\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "Use only KOREAN language to reply.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the chain, including\n",
    "chain = (\n",
    "    prompt\n",
    "    | ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"gpt-4o\",\n",
    "        streaming=True,\n",
    "        callbacks=[StreamCallback()],\n",
    "    )\n",
    "    | JsonOutputParser()\n",
    "    | (lambda x: x[-1][\"Denser_Summary\"])\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "result = chain.invoke({\"ARTICLE\": content})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
