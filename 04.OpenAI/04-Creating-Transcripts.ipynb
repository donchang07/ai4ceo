{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 정보로드를 위한 라이브러리\n",
    "# 설치: pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 토큰 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 오디오파일에 자막생성\n",
    "- response_format=\"srt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open(\"data/채용면접_샘플_01.wav\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    file=audio_file,\n",
    "    model=\"whisper-1\",\n",
    "    language=\"ko\",\n",
    "    response_format=\"srt\",  # 자막 포맷\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YouTube url에서 음성파일을 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import os\n",
    "\n",
    "link = \"https://www.youtube.com/watch?v=ZsQX7x_KWjo&t=2851s\"\n",
    "\n",
    "yt = YouTube(link)\n",
    "filename = yt.streams.filter(only_audio=True).first().download()\n",
    "renamed_file = filename.replace(\".mp4\", \".mp3\")\n",
    "os.rename(filename, renamed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(renamed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 MP3를  WAV 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "\n",
    "def convert_mp3_to_wav(filepath):\n",
    "    # WAV 파일 경로\n",
    "    wav_file_path = filepath.replace(\".mp3\", \".wav\")\n",
    "\n",
    "    # MP4 파일 로드\n",
    "    audio_clip = AudioFileClip(filepath)\n",
    "\n",
    "    # WAV 형식으로 오디오 추출 및 저장\n",
    "    audio_clip.write_audiofile(wav_file_path, fps=44100, nbytes=2, codec=\"pcm_s16le\")\n",
    "    return wav_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file = convert_mp3_to_wav(renamed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# 오디오 파일 불러오기\n",
    "audio = AudioSegment.from_file(wav_file, format=\"wav\")\n",
    "\n",
    "total_length = len(audio)\n",
    "length_per_chunk = 60 * 1000  # 60초\n",
    "\n",
    "if not os.path.exists(\".tmp\"):\n",
    "    os.mkdir(\".tmp\")\n",
    "\n",
    "folder_path = os.path.join(\".tmp\", wav_file[:-4])\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "chunks = []\n",
    "for i in range(0, total_length, length_per_chunk):\n",
    "    chunk_file_path = os.path.join(folder_path, f\"{i}.wav\")\n",
    "    audio[i : i + length_per_chunk].export(chunk_file_path, format=\"wav\")\n",
    "    chunks.append(chunk_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "def adjust_timestamps(transcript, minutes=1):\n",
    "    # Define the regular expression pattern for timestamps\n",
    "    timestamp_pattern = re.compile(r\"(\\d{2}:\\d{2}:\\d{2},\\d{3})\")\n",
    "\n",
    "    # Function to add minutes to a timestamp\n",
    "    def add_minutes(timestamp_str, minutes):\n",
    "        timestamp = datetime.strptime(timestamp_str, \"%H:%M:%S,%f\")\n",
    "        adjusted_timestamp = timestamp + timedelta(minutes=minutes)\n",
    "        return adjusted_timestamp.strftime(\"%H:%M:%S,%f\")[:-3]\n",
    "\n",
    "    # Replace timestamps in the transcript\n",
    "    adjusted_transcript = timestamp_pattern.sub(\n",
    "        lambda match: add_minutes(match.group(1), minutes), transcript\n",
    "    )\n",
    "    return adjusted_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(chunk)\n",
    "    audio_file = open(chunk, \"rb\")\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "        file=audio_file,\n",
    "        model=\"whisper-1\",\n",
    "        language=\"ko\",\n",
    "        response_format=\"srt\",\n",
    "        temperature=0.01,\n",
    "    )\n",
    "    transcripts.append(adjust_timestamps(transcript, minutes=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_transcripts(*transcripts):\n",
    "    merged_transcript = \"\"\n",
    "    current_number = 1\n",
    "\n",
    "    for transcript in transcripts:\n",
    "        # Split the transcript into segments\n",
    "        segments = transcript.strip().split(\"\\n\\n\")\n",
    "        for segment in segments:\n",
    "            # Split each segment into lines\n",
    "            lines = segment.split(\"\\n\")\n",
    "            # Replace the number at the beginning of each segment with the correct sequence number\n",
    "            lines[0] = str(current_number)\n",
    "            # Increment the sequence number\n",
    "            current_number += 1\n",
    "            # Reassemble the segment\n",
    "            merged_transcript += \"\\n\".join(lines) + \"\\n\\n\"\n",
    "\n",
    "    return merged_transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge_transcripts(*transcripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_transcript = merge_transcripts(*transcripts)\n",
    "print(merged_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.srt\", \"w\") as f:\n",
    "    f.write(merged_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "MAX_COMPLETION_TOKENS = 4096\n",
    "MAX_CONTEXT_LENGTH = 8192  # GPT-4의 일반적인 컨텍스트 길이\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def chunk_text(text: str, max_chunk_tokens: int = 3000) -> list[str]:\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_tokens = 0\n",
    "    \n",
    "    for sentence in text.split(\". \"):\n",
    "        sentence_tokens = count_tokens(sentence)\n",
    "        if current_tokens + sentence_tokens > max_chunk_tokens:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "            current_tokens = sentence_tokens\n",
    "        else:\n",
    "            current_chunk += sentence + \". \"\n",
    "            current_tokens += sentence_tokens\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def process_chunk(chunk: str, system_prompt: str) -> str:\n",
    "    prompt_tokens = count_tokens(system_prompt) + count_tokens(chunk)\n",
    "    max_response_tokens = min(MAX_COMPLETION_TOKENS, MAX_CONTEXT_LENGTH - prompt_tokens - 100)\n",
    "\n",
    "    if max_response_tokens <= 0:\n",
    "        return \"Error: 입력 텍스트가 너무 깁니다.\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.1,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": chunk},\n",
    "            ],\n",
    "            max_tokens=max_response_tokens,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: API 호출 중 오류 발생 - {str(e)}\"\n",
    "\n",
    "def format_summary(summary: str) -> str:\n",
    "    lines = summary.split('\\n')\n",
    "    formatted_lines = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            match = re.match(r'^(\\d{2}:\\d{2})\\s+(.+)$', line)\n",
    "            if match:\n",
    "                time, content = match.groups()\n",
    "                if not any(emoji in content for emoji in ['🔶', '👋', '👀', '💡', '🎯', '📊', '🔑', '💻', '🤔', '📝']):\n",
    "                    content = '🔶 ' + content\n",
    "                formatted_lines.append(f\"{time} {content}\")\n",
    "            else:\n",
    "                formatted_lines.append(line)\n",
    "    return \"\\n\".join(formatted_lines)\n",
    "\n",
    "def post_processing(instruction: str) -> str:\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 비디오 자막을 분석하고 요약하는 AI 어시스턴트입니다. 주어진 자막 정보를 바탕으로 다음 작업을 수행해야 합니다:\n",
    "    1. 중요한 주제를 시간 순서에 맞게 선정하세요.\n",
    "    2. 각 주제에 대해 한 줄 요약을 작성하세요.\n",
    "    3. 각 주제가 시작되는 시간을 mm:ss(분:초) 형식으로 기록하세요.\n",
    "    4. 각 요약 문장에 적합한 이모지를 추가하세요.\n",
    "    5. 요약은 한글로 작성하세요.\n",
    "    6. 주제는 최대한 많이 추출해 주세요.\n",
    "    7. 시간 표기에 오류가 없도록 주의하세요.\n",
    "\n",
    "    출력 형식:\n",
    "    mm:ss 🔶 주제에 대한 한 줄 요약\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = chunk_text(instruction)\n",
    "    summaries = []\n",
    "\n",
    "    print(f\"총 {len(chunks)}개의 청크로 나누어 처리합니다.\\n\")\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\n청크 {i+1}/{len(chunks)} 처리 중...\\n\")\n",
    "        summary = process_chunk(chunk, system_prompt)\n",
    "        summaries.append(summary)\n",
    "        print(summary)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    final_summary = \"\\n\".join(summaries)\n",
    "    formatted_summary = format_summary(final_summary)\n",
    "\n",
    "    return formatted_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"주어진 비디오 \"자막정보\" 를 바탕으로 [요청사항]을 차례대로 수행해주세요.\n",
    "[자막정보]\n",
    "{merged_transcript}\n",
    "\n",
    "[요청사항]\n",
    "1. 주어진 [자막정보]에서 중요한 주제를 시간 순서에 맞게 선정하고, 주제가 시작되는 시간을 기록해주세요.\n",
    "2. 주제는 한 줄 요약을 작성하고, 자막에서 주제가 시작되는 시간을 mm:ss(분:초) 형식으로 작성하세요. (예: 00:05 👋 자막 생성 기능에 대한 소개)\n",
    "3. 요약은 한글로 작성해주세요.\n",
    "4. 각 문장에 적합한 emoji를 최대한 활용해 주세요\n",
    "\n",
    "[출력예시]\n",
    "00:12 👋 GPTs 의 주요 개념에 대하여 소개해요\n",
    "03:13 👀 GPTs 의 장단점과 활용 사례에 대하여 자세히 알아봐요\n",
    "\n",
    "[주의사항]\n",
    "- 주제는 최대한 많이 추출해 주세요.\n",
    "- 시간표기에 오류가 없도록 주의해 주세요. 분:초 형식으로 작성합니다. (예: 00:12)\n",
    "\n",
    "run step-by-step. Take a deep breath. You can do it!\n",
    "\"\"\"\n",
    "summary_output = post_processing(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
